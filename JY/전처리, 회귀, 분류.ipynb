{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a52c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1949 entries, 0 to 1948\n",
      "Data columns (total 11 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Country name                      1949 non-null   object \n",
      " 1   year                              1949 non-null   int64  \n",
      " 2   Life Ladder                       1949 non-null   float64\n",
      " 3   Log GDP per capita                1913 non-null   float64\n",
      " 4   Social support                    1936 non-null   float64\n",
      " 5   Healthy life expectancy at birth  1894 non-null   float64\n",
      " 6   Freedom to make life choices      1917 non-null   float64\n",
      " 7   Generosity                        1860 non-null   float64\n",
      " 8   Perceptions of corruption         1839 non-null   float64\n",
      " 9   Positive affect                   1927 non-null   float64\n",
      " 10  Negative affect                   1933 non-null   float64\n",
      "dtypes: float64(9), int64(1), object(1)\n",
      "memory usage: 167.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Country name                                153 non-null    object \n",
      " 1   Regional indicator                          153 non-null    object \n",
      " 2   Ladder score                                153 non-null    float64\n",
      " 3   Standard error of ladder score              153 non-null    float64\n",
      " 4   upperwhisker                                153 non-null    float64\n",
      " 5   lowerwhisker                                153 non-null    float64\n",
      " 6   Logged GDP per capita                       153 non-null    float64\n",
      " 7   Social support                              153 non-null    float64\n",
      " 8   Healthy life expectancy                     153 non-null    float64\n",
      " 9   Freedom to make life choices                153 non-null    float64\n",
      " 10  Generosity                                  153 non-null    float64\n",
      " 11  Perceptions of corruption                   153 non-null    float64\n",
      " 12  Ladder score in Dystopia                    153 non-null    float64\n",
      " 13  Explained by: Log GDP per capita            153 non-null    float64\n",
      " 14  Explained by: Social support                153 non-null    float64\n",
      " 15  Explained by: Healthy life expectancy       153 non-null    float64\n",
      " 16  Explained by: Freedom to make life choices  153 non-null    float64\n",
      " 17  Explained by: Generosity                    153 non-null    float64\n",
      " 18  Explained by: Perceptions of corruption     153 non-null    float64\n",
      " 19  Dystopia + residual                         153 non-null    float64\n",
      "dtypes: float64(18), object(2)\n",
      "memory usage: 24.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 200)    \n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 20)\n",
    "\n",
    "\n",
    "# 1. 데이터 가져오기. 데이터 정보 확인\n",
    "# 2005년부터 2020년까지의 16년간의 데이터\n",
    "world_2020 = pd.read_csv('data/projectdata/world-happiness-report.csv')  \n",
    "world_2020.info() \n",
    "world_2020.shape   # 1949행, 11열 \n",
    "\n",
    "happy20 = pd.read_csv('data/projectdata/2020.csv')\n",
    "happy20.info()     # 결측치 없음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d420ed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Somalia' 'South Sudan']\n",
      "['Hong Kong S.A.R. of China' 'Kosovo']\n",
      "['Somalia' 'South Sudan']\n",
      "['China' 'Turkmenistan']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Country name                        0\n",
       "year                                0\n",
       "Life Ladder                         0\n",
       "Log GDP per capita                  0\n",
       "Social support                      0\n",
       "Healthy life expectancy at birth    0\n",
       "Freedom to make life choices        0\n",
       "Generosity                          0\n",
       "Perceptions of corruption           0\n",
       "Positive affect                     0\n",
       "Negative affect                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 결측치 처리\n",
    "\n",
    "# 원본데이터를 통한 결측치 분석\n",
    "# 피처의 값이 하나도 존재하지 않는 경우 ( 나라 : 피처명 ) => 결측치가 존재하는 행을 삭제하면 나라도 삭제되는 문제 발생\n",
    "# Hongkong S.A.R. of China, Kosovo : Healthy life expectancy at birth\n",
    "# China, Turkmenistan : Perceptions of corruption\n",
    "# Somalia, South Sudan : Log GDP per capita, Generosity\n",
    "# Somaliland region, North Cyprus : Log GDP per capita, Healthy life expectancy at birth, Generosity\n",
    "\n",
    "# 일년치만 관측된 나라 중 3개의 피처가 결측치인 경우\n",
    "# Oman(2011), Cuba(2006), Maldives(2018) \n",
    "# 중요 6가지 지표 중 (http://naver.me/FGoFBWHm ) 절반 이상이 없는 것은 분석의 의미가 없다고 생각 => 삭제 \n",
    "\n",
    "\n",
    "\n",
    "# (1) 결측치 개수 확인 \n",
    "world_2020.isnull().sum()\n",
    "world_2020.isnull().sum().sum()  # 373 \n",
    "\n",
    "\n",
    "# (2) 결측치가 3개 이상 있는 행을 삭제  \n",
    "world_2020 = world_2020.dropna(thresh=9, axis=0)\n",
    "# thresh=9 : nan이 아닌 값(정상값)이 최소 9개 이상 나와야 함. \n",
    "world_2020.isnull().sum().sum()   #239\n",
    "\n",
    "\n",
    "# (3) 각 나라별 피처의 평균값으로 결측치 대체\n",
    "world_2020['Log GDP per capita'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Log GDP per capita'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Social support'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Social support'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Healthy life expectancy at birth'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Healthy life expectancy at birth'].transform('mean'),inplace=True)\n",
    "        \n",
    "world_2020['Freedom to make life choices'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Freedom to make life choices'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Generosity'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Generosity'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Perceptions of corruption'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Perceptions of corruption'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Positive affect'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Positive affect'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020['Negative affect'].fillna(world_2020.groupby('Country name')\\\n",
    "                                        ['Negative affect'].transform('mean'),inplace=True)\n",
    "\n",
    "world_2020.isnull().sum().sum()   # 60\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (4) 나라별 피처의 값이 아예 존재하지 않는 경우 happy20 데이터에서 찾아서 채우기\n",
    "world_2020.isnull().sum()  \n",
    "# Log GDP per capita : 7, Healthy life expectancy at birth : 22,\n",
    "# Generosity : 7, Perceptions of corruption : 24\n",
    "\n",
    "mask = world_2020['Log GDP per capita'].isnull()\n",
    "print(world_2020[mask]['Country name'].unique())  #  Somalia , South Sudan \n",
    "\n",
    "mask = world_2020['Healthy life expectancy at birth'].isnull()\n",
    "print(world_2020[mask]['Country name'].unique())  # Hong Kong S.A.R. of China, Kosovo\n",
    "\n",
    "mask = world_2020['Generosity'].isnull()\n",
    "print(world_2020[mask]['Country name'].unique())  # Somalia , South Sudan \n",
    "\n",
    "mask = world_2020['Perceptions of corruption'].isnull()\n",
    "print(world_2020[mask]['Country name'].unique())  # China , Turkmenistan\n",
    "\n",
    "\n",
    "# (4)-1. Somalia, South Sudan => Log GDP per capita, Generosity 구하기 \n",
    "# Somalia가 happy20 데이터에 없음 => 삭제\n",
    "mask = world_2020['Country name']=='Somalia'  \n",
    "world_2020.drop(world_2020[mask].index,inplace=True)\n",
    "world_2020.isnull().sum().sum()  # 54 (Log GDP per capita, Generosity 각 3개씩 삭제됨)\n",
    "\n",
    "# 인덱스 재정렬 \n",
    "world_2020.reset_index(drop=True, inplace=True)  \n",
    "\n",
    "# South Sudan의 Log GDP per capita, Generosity happy20에서 구해서 결측값 채우기\n",
    "# Log GDP per capita\n",
    "mask = happy20['Country name'] =='South Sudan'\n",
    "SSudan_GDP_20 = happy20[mask]['Logged GDP per capita'].values[0]\n",
    "SSudan_GDP_20  # 7.425359726\n",
    "\n",
    "world_2020['Log GDP per capita'].fillna(SSudan_GDP_20,inplace=True)\n",
    "world_2020.isnull().sum()  \n",
    "\n",
    "# Generosity\n",
    "mask = happy20['Country name'] =='South Sudan'\n",
    "SSudan_Generosity_20 = happy20[mask]['Generosity'].values[0]\n",
    "SSudan_Generosity_20  # 0.016518548\n",
    "\n",
    "world_2020['Generosity'].fillna(SSudan_Generosity_20,inplace=True)\n",
    "world_2020.isnull().sum()  \n",
    "\n",
    "\n",
    "# (4)-2. Hong Kong S.A.R. of China, Kosovo => Healthy life expectancy at birth\n",
    "\n",
    "# Hong Kong S.A.R. of China\n",
    "mask = happy20['Country name'] =='Hong Kong S.A.R. of China'\n",
    "HKSAR_HLE_20 = happy20[mask]['Healthy life expectancy'].values[0]\n",
    "HKSAR_HLE_20   # 76.77170563\n",
    "\n",
    "mask = world_2020['Country name'] =='Hong Kong S.A.R. of China'\n",
    "world_2020[mask]\n",
    "world_2020.loc[692:702,'Healthy life expectancy at birth'].replace(np.nan,HKSAR_HLE_20,inplace=True)\n",
    "world_2020.isnull().sum()  \n",
    "\n",
    "# Kosovo\n",
    "mask = happy20['Country name'] =='Kosovo'\n",
    "KSV_HLE_20 = happy20[mask]['Healthy life expectancy'].values[0]\n",
    "KSV_HLE_20   # 63.88555527 \n",
    "\n",
    "mask = world_2020['Country name'] =='Kosovo'\n",
    "world_2020[mask]\n",
    "world_2020.loc[894:906,'Healthy life expectancy at birth'].replace(np.nan,KSV_HLE_20,inplace=True)\n",
    "world_2020.isnull().sum()  \n",
    "\n",
    "\n",
    "# (4)-3. China , Turkmenistan => Perceptions of corruption\n",
    "# Turkmenistan\n",
    "mask = happy20['Country name'] =='Turkmenistan'\n",
    "T_PC_20 = happy20[mask]['Perceptions of corruption'].values[0]\n",
    "T_PC_20   # 0.883691847\n",
    "\n",
    "mask = world_2020['Country name'] =='Turkmenistan'\n",
    "world_2020[mask].index\n",
    "world_2020.loc[1729:1739,'Perceptions of corruption'].replace(np.nan,T_PC_20,inplace=True)\n",
    "world_2020.isnull().sum()  \n",
    "\n",
    "# China\n",
    "mask = happy20['Country name'] =='China'\n",
    "C_PC_20 = happy20[mask]['Perceptions of corruption'].values[0]\n",
    "C_PC_20   # 0.7539711\n",
    "\n",
    "mask = world_2020['Country name'] =='China'\n",
    "world_2020[mask].index\n",
    "world_2020.loc[338:352,'Perceptions of corruption'].replace(np.nan,C_PC_20,inplace=True)\n",
    "world_2020.isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e76fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7416343112439837\n",
      "0.7446313433457559\n",
      "0.5707768339431321\n",
      "0.565258320347989\n"
     ]
    }
   ],
   "source": [
    "###### 회귀분석######\\\n",
    "\n",
    "# 1. 독립속성과 종속속성 나누기\n",
    "# 1-1. 독립속성 선택 : Country name, year, Life Ladder, Positive affect, Negative affect 제외한 나머지 피처 \n",
    "X = world_2020[['Log GDP per capita','Social support', 'Healthy life expectancy at birth',\n",
    "       'Freedom to make life choices', 'Generosity','Perceptions of corruption']] \n",
    "# 1-2. 종속속성 선택\n",
    "y = world_2020['Life Ladder']\n",
    "\n",
    "\n",
    "# 2. 정규화하기\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 3. train 데이터와 test 데이터로 구분\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "\n",
    "# 4. 회귀모델 생성\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# 5. 학습하기\n",
    "model = lr.fit(X_train, y_train)\n",
    "\n",
    "# 6. 평가\n",
    "# 6-1. R2 출력하기\n",
    "print(model.score(X_train,y_train))   # 0.7416343112439837\n",
    "print(model.score(X_test,y_test))     # 0.7446313433457559\n",
    "\n",
    "# 6-2. RMSE score 출력하기. MSE가 작을수록 좋은 것 \n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pre = lr.predict(X_train)\n",
    "rmse = sqrt(mean_squared_error(y_train,y_pre))\n",
    "print(rmse)   # 0.5707768339431321\n",
    "\n",
    "y_pre = lr.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test,y_pre))\n",
    "print(rmse)   # 0.565258320347989\n",
    "\n",
    "\n",
    "\n",
    "# r2 score 값은 1에 가까울수록 성능이 좋다.\n",
    "# 학습데이터의 r2score와 test 데이터의 r2score는 값이 비슷한 경우가 학습데이터가 모델을 잘 설명하는 데이터."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e88c373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '3']\n"
     ]
    }
   ],
   "source": [
    "###### 그룹화하기 ######\n",
    "\n",
    "# 행복지수 기준으로 내림차순 \n",
    "world_2020.sort_values(by='Life Ladder', ascending=False,inplace=True)\n",
    "\n",
    "# 인덱스 재정렬\n",
    "world_2020.reset_index(drop=True, inplace=True)  \n",
    "\n",
    "# 1,2,3 으로 그룹화\n",
    "\n",
    "newlist = []\n",
    "for idx in world_2020.index :\n",
    "    if idx <= 635 :\n",
    "        newlist += ['1']\n",
    "    elif idx <= 1271 :\n",
    "        newlist += ['2']\n",
    "    else :\n",
    "        newlist += ['3']\n",
    "world_2020['group'] = newlist\n",
    "print(world_2020['group'].unique())   # ['1' '2' '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff9c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수:  (1525, 6)\n",
      "test data 개수:  (382, 6)\n"
     ]
    }
   ],
   "source": [
    "####### 데이터 분리 #######\n",
    "\n",
    "# 독립속성과 종속속성 나누기\n",
    "X = world_2020[['Log GDP per capita','Social support', 'Healthy life expectancy at birth',\n",
    "       'Freedom to make life choices', 'Generosity','Perceptions of corruption']] \n",
    "y = world_2020['group']\n",
    "\n",
    "\n",
    "# 정규화하기\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# train 데이터와 test 데이터로 구분\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "print('train data 개수: ', X_train.shape)   # (1525, 6)\n",
    "print('test data 개수: ', X_test.shape)     # (382, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a093c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '2' '3' '1' '2' '1' '1' '2' '1' '3']\n",
      "['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
      "[[107  13   0]\n",
      " [ 24  93  17]\n",
      " [  4  16 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.89      0.84       120\n",
      "           2       0.76      0.69      0.73       134\n",
      "           3       0.86      0.84      0.85       128\n",
      "\n",
      "    accuracy                           0.81       382\n",
      "   macro avg       0.81      0.81      0.81       382\n",
      "weighted avg       0.81      0.81      0.80       382\n",
      "\n",
      "정확도(Accuracy) : 0.806282722513089\n"
     ]
    }
   ],
   "source": [
    "###### 1. KNN 분류 모형 ######\n",
    "\n",
    "# KNN 분류 모형 - sklearn 사용\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "print(y_hat[0:10])          # ['2' '2' '3' '1' '2' '1' '1' '2' '1' '3']\n",
    "print(y_test.values[0:10])  # ['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
    "\n",
    "# 성능평가하기\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(knn_matrix)\n",
    "\n",
    "'''\n",
    "[[107  13   0]\n",
    " [ 24  93  17]\n",
    " [  4  16 108]]\n",
    "'''\n",
    "knn_report = metrics.classification_report(y_test, y_hat)\n",
    "print(knn_report)\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.79      0.89      0.84       120\n",
    "           2       0.76      0.69      0.73       134\n",
    "           3       0.86      0.84      0.85       128\n",
    "\n",
    "    accuracy                           0.81       382\n",
    "   macro avg       0.81      0.81      0.81       382\n",
    "weighted avg       0.81      0.81      0.80       382\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"정확도(Accuracy) :\", accuracy_score(y_test,y_hat))   # 0.806282722513089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4382b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '2' '3' '1' '2' '1' '1' '1' '1' '3']\n",
      "['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
      "[[105  15   0]\n",
      " [ 20  93  21]\n",
      " [  1  16 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.88      0.85       120\n",
      "           2       0.75      0.69      0.72       134\n",
      "           3       0.84      0.87      0.85       128\n",
      "\n",
      "    accuracy                           0.81       382\n",
      "   macro avg       0.81      0.81      0.81       382\n",
      "weighted avg       0.81      0.81      0.81       382\n",
      "\n",
      "정확도(Accuracy) :  0.8089005235602095\n"
     ]
    }
   ],
   "source": [
    "###### 2. SVM 분류 모형 ######\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_hat= svm_model.predict(X_test)\n",
    "print(y_hat[0:10])             # ['3' '2' '3' '1' '2' '1' '1' '1' '1' '3']\n",
    "print(y_test.values[0:10])     # ['3' '2' '2' '1' '2' '1' '2' '2' '1' '3'] \n",
    "\n",
    "# 모형 성능 평가\n",
    "from sklearn import metrics\n",
    "svm_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(svm_matrix)\n",
    "'''\n",
    "[[105  15   0]\n",
    " [ 20  93  21]\n",
    " [  1  16 111]]\n",
    "'''\n",
    "svm_report = metrics.classification_report(y_test, y_hat)\n",
    "print(svm_report)\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.83      0.88      0.85       120\n",
    "           2       0.75      0.69      0.72       134\n",
    "           3       0.84      0.87      0.85       128\n",
    "\n",
    "    accuracy                           0.81       382\n",
    "   macro avg       0.81      0.81      0.81       382\n",
    "weighted avg       0.81      0.81      0.81       382\n",
    "'''\n",
    "print(\"정확도(Accuracy) : \", accuracy_score(y_test,y_hat))    #  0.8089005235602095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010d140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '2' '3' '1' '3' '2' '1' '2' '1' '3']\n",
      "['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
      "[[ 88  31   1]\n",
      " [ 12  98  24]\n",
      " [  2  17 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.73      0.79       120\n",
      "           2       0.67      0.73      0.70       134\n",
      "           3       0.81      0.85      0.83       128\n",
      "\n",
      "    accuracy                           0.77       382\n",
      "   macro avg       0.78      0.77      0.77       382\n",
      "weighted avg       0.78      0.77      0.77       382\n",
      "\n",
      "정확도(Accuracy) :  0.7722513089005235\n"
     ]
    }
   ],
   "source": [
    "###### 3. Decision Tree 분류 모형 #####\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "print(y_hat[0:10])           # ['3' '2' '3' '1' '3' '2' '1' '2' '1' '3']\n",
    "print(y_test.values[0:10])   # ['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
    "\n",
    "# 모형 성능 평가\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "'''\n",
    "[[ 88  31   1]\n",
    " [ 12  98  24]\n",
    " [  2  17 109]]\n",
    "'''\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.86      0.73      0.79       120\n",
    "           2       0.67      0.73      0.70       134\n",
    "           3       0.81      0.85      0.83       128\n",
    "\n",
    "    accuracy                           0.77       382\n",
    "   macro avg       0.78      0.77      0.77       382\n",
    "weighted avg       0.78      0.77      0.77       382\n",
    "'''\n",
    "# 정확도\n",
    "print(\"정확도(Accuracy) : \", accuracy_score(y_test,y_hat))   #  0.7722513089005235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d941e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '2' '3' '1' '2' '1' '1' '1' '1' '3']\n",
      "['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
      "[[103  17   0]\n",
      " [ 20  94  20]\n",
      " [  1  26 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.86      0.84       120\n",
      "           2       0.69      0.70      0.69       134\n",
      "           3       0.83      0.79      0.81       128\n",
      "\n",
      "    accuracy                           0.78       382\n",
      "   macro avg       0.78      0.78      0.78       382\n",
      "weighted avg       0.78      0.78      0.78       382\n",
      "\n",
      "정확도(Accuracy) :  0.7801047120418848\n"
     ]
    }
   ],
   "source": [
    "###### 4. 로지스틱회귀분석 ######\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=4)\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "print(y_hat[:10])           # ['3' '2' '3' '1' '2' '1' '1' '1' '1' '3']\n",
    "print(y_test.values[:10])   # ['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
    "\n",
    "\n",
    "# 모형 성능 평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confmat = confusion_matrix(y_test,y_hat)\n",
    "print(confmat)\n",
    "'''\n",
    "[[103  17   0]\n",
    " [ 20  94  20]\n",
    " [  1  26 101]]\n",
    "'''\n",
    "logistic_report = metrics.classification_report(y_test, y_hat)\n",
    "print(logistic_report)\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.83      0.86      0.84       120\n",
    "           2       0.69      0.70      0.69       134\n",
    "           3       0.83      0.79      0.81       128\n",
    "\n",
    "    accuracy                           0.78       382\n",
    "   macro avg       0.78      0.78      0.78       382\n",
    "weighted avg       0.78      0.78      0.78       382\n",
    "'''\n",
    "print(\"정확도(Accuracy) : \", accuracy_score(y_test,y_hat))    # 0.7801047120418848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a113e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '2' '3' '1' '2' '1' '1' '2' '1' '3']\n",
      "['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
      "[[101  18   1]\n",
      " [ 20  92  22]\n",
      " [  1  16 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.84      0.83       120\n",
      "           2       0.73      0.69      0.71       134\n",
      "           3       0.83      0.87      0.85       128\n",
      "\n",
      "    accuracy                           0.80       382\n",
      "   macro avg       0.80      0.80      0.80       382\n",
      "weighted avg       0.79      0.80      0.79       382\n",
      "\n",
      "정확도(Accuracy) : 0.7958115183246073\n"
     ]
    }
   ],
   "source": [
    "###### 5. GradientBoostingClassifier 모델 ######\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "print(y_hat[:10])          # ['3' '2' '3' '1' '2' '1' '1' '2' '1' '3']\n",
    "print(y_test[:10].values)  # ['3' '2' '2' '1' '2' '1' '2' '2' '1' '3']\n",
    "\n",
    "# 모형 성능 평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confmat = confusion_matrix(y_test,y_hat)\n",
    "print(confmat)\n",
    "'''\n",
    "[[100  19   1]\n",
    " [ 20  92  22]\n",
    " [  1  16 111]]\n",
    "'''\n",
    "GBC_report = metrics.classification_report(y_test, y_hat)\n",
    "print(GBC_report)\n",
    "'''\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.83      0.83      0.83       120\n",
    "           2       0.72      0.69      0.70       134\n",
    "           3       0.83      0.87      0.85       128\n",
    "\n",
    "    accuracy                           0.79       382\n",
    "   macro avg       0.79      0.80      0.79       382\n",
    "weighted avg       0.79      0.79      0.79       382\n",
    "'''\n",
    "\n",
    "# 정확도 출력하기\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"정확도(Accuracy) :\", accuracy_score(y_test,y_hat))   # 0.7931937172774869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4e200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
